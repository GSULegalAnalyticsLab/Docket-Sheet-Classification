{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Concatenated_text_file(Excel_file, New_file_name):     \n",
    "    # Create new write file\n",
    "    New_File = open(str(New_file_name) + '.txt','w')\n",
    "     \n",
    "    # Create Loop Through List of Directories\n",
    "    for row in Excel_file:\n",
    "        \n",
    "        # Write files to new file\n",
    "        New_File.write(str(row))\n",
    "        New_File.write('\\n')\n",
    "    # Close File\n",
    "    New_File.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT TARGET FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_docketFile():\n",
    "    '''\n",
    "    Input      = None\n",
    "    Operations = Read file, select columns, eliminate time-period = None\n",
    "    Return     = dataframe. \n",
    "    '''\n",
    "    # Read in Excel File\n",
    "    df_docket_sheets = pd.read_excel('2018-02-18 Docket Review.xlsx')\n",
    "    # Select columns\n",
    "    df_docket_sheets_fit = df_docket_sheets.iloc[:,0:-1]\n",
    "    # Select rows != None\n",
    "    TimePeriod_notNone = df_docket_sheets_fit['Time Period'] > 0\n",
    "    # Return dataframe\n",
    "    return df_docket_sheets_fit[TimePeriod_notNone]\n",
    "\n",
    "df_docket_sheets_drop_none = import_docketFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCATENATE TEXT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def concat_docket_text(dataframe):\n",
    "    '''\n",
    "    Input  = dataframe\n",
    "    Output = None, write concatenated text file to cwd\n",
    "    '''\n",
    "    # Select docket text column\n",
    "    df_docket_text = df_docket_sheets_drop_none['docket_text']\n",
    "    # Iterate over rows and concatenate text. Write to file. \n",
    "    create_Concatenated_text_file(df_docket_text, 'Concatenated_Docket_Text')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT CONCATENATED TEXT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_concatTxt():\n",
    "    # Import Concat Text File\n",
    "    File = 'Concatenated_Docket_Text.txt'\n",
    "    File_open = open(File) \n",
    "    return File_open.read()\n",
    "\n",
    "docket_sheet_concatenatedText_File = import_concatTxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE SET FROM CONCATENATED TEXT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_from_text(Text_file):\n",
    "    '''\n",
    "    Input      = Text File\n",
    "    Operations = Tokenize, lowercase, strip punctuation/stopwords/nonAlpha\n",
    "    Return     = Set of alpha tokens \n",
    "    '''\n",
    "    # Strip Lists\n",
    "    Punct_list = [punct for punct in string.punctuation]\n",
    "    Stopwords = nltk.corpus.stopwords.words('english')\n",
    "    # Tokenize Text\n",
    "    Docket_text_tokenized = nltk.word_tokenize(docketSheet_concatenatedText_File)\n",
    "    # Convert tokens to lowercase\n",
    "    Docket_text_tok_lowercase = (token.lower() for token in Docket_text_tokenized)\n",
    "    # Strip Punctuation\n",
    "    Docket_text_tok_stripPunct = filter(lambda x: (x not in Punct_list), Docket_text_tok_lowercase)\n",
    "    # Strip Stopwords\n",
    "    Docket_text_strip_stopWords = filter(lambda x: (x not in Stopwords), Docket_text_tok_stripPunct)\n",
    "    # Strip Non-Alpha\n",
    "    Docket_text_strip_nonAlpha = filter(lambda x: x.isalpha(), Docket_text_strip_stopWords)\n",
    "    # Return set of Docket_text\n",
    "    return set(Docket_text_strip_nonAlpha)\n",
    "\n",
    "Docket_text_set = create_set_from_text(docketSheet_concatenatedText_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE FREQUENCY DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
