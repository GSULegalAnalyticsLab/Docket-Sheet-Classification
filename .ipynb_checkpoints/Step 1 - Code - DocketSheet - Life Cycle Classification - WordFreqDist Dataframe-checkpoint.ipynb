{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n",
    "import Step1_Module as dsc_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE OBJECT FOR DOCKET SHEET EXCEL FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Docket_sheet_file = r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\2018-02-18 Docket Review.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A DATAFRAME WHOSE INDEX IS THE SET OF WORDS AND COLUMNS THE FREQ DIST FOR EACH STAGE OF THE LIFE CYCLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_code_Pipeline_create_dataframe_setWord_freqDist(Docket_sheet_file):\n",
    "    '''The purpose of this master code pipeline is to pipeline all of the functions required to create the word frequency distribution dataframe \n",
    "       for each life cycle of the Docket Sheet\n",
    "       \n",
    "       Input       = Docket sheet file as an excel spreadsheet.  We will read in using pandas. \n",
    "       Operations  = 1.) Import the docket sheet, delimit columns, remove rows where time-period = 0/None\n",
    "                     2.) Concatenate all of the text located in the text column of the Docket Sheet for which a time period has been assigned.\n",
    "                         Write the text file to current-working-directory.\n",
    "                     3.) Import into memor the concatenated text file. \n",
    "                     4.) Tokenize text file, clean tokens of punctuation, stop words and limit to isalpha(). \n",
    "                     5.) Create a set of from our tokenized and cleaned text.  This set will constitute the basis for our word frequency distribution. \n",
    "                     6.) Create a dataframe whose index is the above create set of words.  Generate the word frequency for each life cycle stage for\n",
    "                         this set of words. Return to the user the dataframe in memory. \n",
    "    '''\n",
    "    \n",
    "    # 1.) Import Target File / Delimit Columns / Remove Rows if Period = None\n",
    "    df_Master_DocketSheet_File = dsc_m.import_docket_sheet_file(Docket_sheet_file)\n",
    "    \n",
    "    # 2.) Concatenate Text From Docket Sheet Time Periods\n",
    "    dsc_m.create_Concatenated_text_file(df_Master_DocketSheet_File, 'Concatenate_DocketSheet_Text')\n",
    "    \n",
    "    # 3.) Import Into Memory Concatenated Text File\n",
    "    Concat_txt_File = dsc_m.import_concatTxt('Concatenated_Docket_Text.txt')\n",
    "    \n",
    "    # 4.) Clean & Tokenize Concatenated Text File\n",
    "    Clean_tokenized_concatText = dsc_m.clean_andTokenize_text(Concat_txt_File)\n",
    "    \n",
    "    # 5.) Create Set of Words From Clean & Tokenized Concat Text File\n",
    "    Set_tokenized_concatText = list(set(Clean_tokenized_concatText))\n",
    "    \n",
    "    # 6.) Create & Return Word Frequency Distribution Dataframe\n",
    "    return dsc_m.create_dataframe_setWord_freqDist(df_Master_DocketSheet_File, Set_tokenized_concatText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Word_Freq_Dist = master_code_Pipeline_create_dataframe_setWord_freqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE DATAFRAME TO EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc_m.write_to_excel(df_docketsheet_wordSet, 'DocketSheet_wordSet_Freq_Dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT WORD FREQUENCY DISTRIBUTION DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wordFreq = pd.read_excel('DocketSheet_wordSet_Freq_Dist.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
