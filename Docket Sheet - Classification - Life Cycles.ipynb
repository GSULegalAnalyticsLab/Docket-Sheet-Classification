{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n",
    "import Docket_Sheet_Classification_module as dsc_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE OBJECT FOR DOCKET SHEET EXCEL FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Docket_sheet_file = r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\2018-02-18 Docket Review.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A DATAFRAME WHOSE INDEX IS THE SET OF WORDS AND COLUMNS THE FREQ DIST FOR EACH STAGE OF THE LIFE CYCLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_code_Pipeline_create_dataframe_setWord_freqDist(Docket_sheet_file):\n",
    "    '''The purpose of this master code pipeline is to pipeline all of the functions required to create the word frequency distribution dataframe \n",
    "       for each life cycle of the Docket Sheet\n",
    "       \n",
    "       Input       = Docket sheet file as an excel spreadsheet.  We will read in using pandas. \n",
    "       Operations  = 1.) Import the docket sheet, delimit columns, remove rows where time-period = 0/None\n",
    "                     2.) Concatenate all of the text located in the text column of the Docket Sheet for which a time period has been assigned.\n",
    "                         Write the text file to current-working-directory.\n",
    "                     3.) Import into memor the concatenated text file. \n",
    "                     4.) Tokenize text file, clean tokens of punctuation, stop words and limit to isalpha(). \n",
    "                     5.) Create a set of from our tokenized and cleaned text.  This set will constitute the basis for our word frequency distribution. \n",
    "                     6.) Create a dataframe whose index is the above create set of words.  Generate the word frequency for each life cycle stage for\n",
    "                         this set of words. Return to the user the dataframe in memory. \n",
    "    '''\n",
    "    \n",
    "    # 1.) Import Target File / Delimit Columns / Remove Rows if Period = None\n",
    "    df_Master_DocketSheet_File = dsc_m.import_docket_sheet_file(Docket_sheet_file)\n",
    "    \n",
    "    # 2.) Concatenate Text From Docket Sheet Time Periods\n",
    "    dsc_m.create_Concatenated_text_file(df_Master_DocketSheet_File, 'Concatenate_DocketSheet_Text')\n",
    "    \n",
    "    # 3.) Import Into Memory Concatenated Text File\n",
    "    Concat_txt_File = dsc_m.import_concatTxt('Concatenated_Docket_Text.txt')\n",
    "    \n",
    "    # 4.) Clean & Tokenize Concatenated Text File\n",
    "    Clean_tokenized_concatText = dsc_m.clean_andTokenize_text(Concat_txt_File)\n",
    "    \n",
    "    # 5.) Create Set of Words From Clean & Tokenized Concat Text File\n",
    "    Set_tokenized_concatText = list(set(Clean_tokenized_concatText))\n",
    "    \n",
    "    # 6.) Create & Return Word Frequency Distribution Dataframe\n",
    "    return dsc_m.create_dataframe_setWord_freqDist(df_Master_DocketSheet_File, Set_tokenized_concatText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Word_Freq_Dist = master_code_Pipeline_create_dataframe_setWord_freqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_excel(dataframe, filename):\n",
    "    import pandas as pd\n",
    "    writer = pd.ExcelWriter(filename+'.xlsx')\n",
    "    dataframe.to_excel(writer, sheet_name = 'Data')\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_excel(df_docketsheet_wordSet, 'DocketSheet_wordSet_Freq_Dist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create a dictionary whose keys are the file classes and values the files for each group. \n",
    "    Dict_files_by_class = create_file_list_by_group(Excel_file)\n",
    "    \n",
    "    # Create a Master Dataframe to house final values\n",
    "    Master_dataframe = pd.DataFrame({}, index = list(dataframe_unique_tokens.index))\n",
    "    \n",
    "    # Loop over the dictionary keys\n",
    "    for Class in Dict_files_by_class.keys():\n",
    "        \n",
    "        # Create a list of the files\n",
    "        File_list = list(Dict_files_by_class[Class])\n",
    "        \n",
    "        # Feed each class list trough the word counter\n",
    "        df_single_class_word_count = get_frequencyDist_legal_text(File_list, dataframe_unique_tokens)\n",
    "        \n",
    "        # Merge individual text file columns into one percentage for the given class\n",
    "        df_merged_columns = Merge_dataframe_columns_calc_percentage(Class, df_single_class_word_count)\n",
    "        \n",
    "        # Merge individual dataframes into master dataframe\n",
    "        Master_dataframe[Class] = df_merged_columns[Class]\n",
    "        \n",
    "    # Return the Master Dataframe with the word % for all classes. \n",
    "    return Master_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
